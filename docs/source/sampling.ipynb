{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling\n",
    "\n",
    "In this notebook, picking up where we left off in the \"Getting started\" tutorial, we are going to walk through a round of sampling. And we are even going to set up everything in a reproducable manner as good as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports & Settings\n",
    "\n",
    "First the imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp \n",
    "import pandas as pd\n",
    "\n",
    "import emcee                      # inference and backends for sample storage\n",
    "from multiprocessing import Pool  # for parallelization of the inference\n",
    "\n",
    "import lymph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now some settings, e.g. the name of the HDF5 file we would later like to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_hdf_file = \"./_data/demo.hdf5\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the Model\n",
    "\n",
    "First, we will set up the model as we would normally. In contrast to the \"Getting started\" notebook, we will set up a `Bilateral` model here, but that isn't more complicated. Only the data that needs to be provided to this kind of model needs to have information on the contralateral involvement as well, obviously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = {\n",
    "    ('tumor', 'primary'): ['I', 'II', 'III', 'IV'],\n",
    "    ('lnl'  , 'I'):       ['II'], \n",
    "    ('lnl'  , 'II'):      ['III'],\n",
    "    ('lnl'  , 'III'):     ['IV'],\n",
    "    ('lnl'  , 'IV'):      []\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_model = lymph.Bilateral(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnostic_spsn = {\n",
    "    \"MRI\": [0.63, 0.81],\n",
    "    \"PET\": [0.86, 0.79]\n",
    "}\n",
    "original_model.modalities = diagnostic_spsn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate synthetic data\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    Note\n",
    "\n",
    "    This step can be skipped, as that data is already in the `./_data` directory. But it may also serve as a guide on how to generate synthetic datasets.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_t = 10\n",
    "t = np.arange(max_t + 1)\n",
    "\n",
    "early_p = 0.3\n",
    "late_p = 0.7\n",
    "\n",
    "early_time_dist = sp.stats.binom.pmf(t, max_t, early_p)\n",
    "late_time_dist = sp.stats.binom.pmf(t, max_t, late_p)\n",
    "time_dists = {\"early\": early_time_dist, \"late\": late_time_dist}\n",
    "\n",
    "original_model.ipsi.base_probs   = [0.05, 0.2 , 0.12, 0.1 ]\n",
    "original_model.contra.base_probs = [0.01, 0.06, 0.03, 0.01]\n",
    "original_model.trans_probs = [0.1, 0.3, 0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_data = original_model.generate_dataset(\n",
    "    num_patients=200, \n",
    "    stage_dist=[0.6, 0.4], \n",
    "    time_dists=time_dists\n",
    ")\n",
    "synthetic_data.to_csv(\"./_data/bilateral.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we load the data into the model instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_data = pd.read_csv(\"./_data/bilateral.csv\", header=[0,1,2])\n",
    "original_model.patient_data = synthetic_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Store the model in an HDF5 file\n",
    "\n",
    "And before we proceed any further, we store the specifics of this model instance in an HDF5 file. It will basically store the graph, the modalities with their sensitivities & specificities as well as the just loaded data in the HDF5 file and allow us to recreate an instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rmnldwg/repos/lymph/.venv/lib/python3.8/site-packages/tables/attributeset.py:291: DataTypeWarning: Unsupported type for attribute 'base_symmetric' in node 'model'. Offending HDF5 class: 8\n",
      "  value = self._g_getattr(self._v_node, name)\n",
      "/home/rmnldwg/repos/lymph/.venv/lib/python3.8/site-packages/tables/attributeset.py:291: DataTypeWarning: Unsupported type for attribute 'trans_symmetric' in node 'model'. Offending HDF5 class: 8\n",
      "  value = self._g_getattr(self._v_node, name)\n"
     ]
    }
   ],
   "source": [
    "original_model.to_hdf(\n",
    "    filename=demo_hdf_file, \n",
    "    name=\"original/model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare the likelihood function\n",
    "\n",
    "In the utilities of the `lymph` package we also provide a small wrapper around the awesome [emcee](https://github.com/dfm/emcee) `EnsembleSampler` that allows us to store some inference-specific parameters before sampling and of course the samples themselves after sampling.\n",
    "\n",
    "Let's start with the first part:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plus one dimension for the late T-stage's time parameter\n",
    "ndim = len(original_model.spread_probs) + 1\n",
    "\n",
    "# number of concurrent walkers that sample the space\n",
    "nwalkers = 10 * ndim\n",
    "\n",
    "# define the log-likelihood\n",
    "def log_prob_fn(theta, sys, early_p=0.3, max_t=10):\n",
    "    spread_probs, late_p = theta[:-1], theta[-1]\n",
    "    \n",
    "    if late_p > 1. or late_p < 0.:\n",
    "        return -np.inf\n",
    "    \n",
    "    t = np.arange(max_t + 1)\n",
    "    time_dists={\n",
    "        \"early\": lymph.utils.fast_binomial_pmf(t, max_t, early_p),\n",
    "        \"late\" : lymph.utils.fast_binomial_pmf(t, max_t, late_p)\n",
    "    }\n",
    "    \n",
    "    return sys.marginal_log_likelihood(\n",
    "        spread_probs, t_stages=[\"early\", \"late\"], time_dists=time_dists\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    Warning \n",
    "\n",
    "    The provided log-likelihood function won't be stored anywhere! It is not possible to store arbitrary python code in an HDF5 file and retrieve it automatically in a safe manner.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling\n",
    "\n",
    "For storing the results, we make use of the `HDFBackend` from `emcee`, while the sampling itself can be done any way one pleases. However, we have written a sampling method `run_sampling` that smartly samples until convergence.\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "    See also\n",
    "\n",
    "    The creators of the `emcee` package have laid out how this \"sampling to convergence\" works in a [really nice tutorial](https://emcee.readthedocs.io/en/stable/tutorials/monitor/), which basically served as inspiration to the `run_sampling` method as well as our attempts of storing the model settings in an HDF5 file to begin with.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [04:58<00:00,  1.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max. number of steps reached\n",
      "Acceptance fraction = 19.89%\n",
      "Mean autocorrelation time = 22.04\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# this chain will surely be too short, but it doesn't matter here\n",
    "max_steps = 200\n",
    "\n",
    "# prepare the backend\n",
    "backend = emcee.backends.HDFBackend(\n",
    "    filename=demo_hdf_file,\n",
    "    name=\"original/samples\"\n",
    ")\n",
    "backend.reset(nwalkers, ndim)\n",
    "\n",
    "# use Pool() from multiprocessing for parallelisation\n",
    "with Pool() as pool:\n",
    "    original_sampler = lymph.utils.EnsembleSampler(\n",
    "        nwalkers, ndim, \n",
    "        log_prob_fn, args=[original_model], \n",
    "        pool=pool, backend=backend\n",
    "    )\n",
    "    acor_list = original_sampler.run_sampling(max_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make sure the chain of samples is actually stored by trying to retrieve it from the HDF5 file directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 12)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_backend = emcee.backends.HDFBackend(\n",
    "    filename=demo_hdf_file,\n",
    "    name=\"original/samples\",\n",
    "    read_only=True\n",
    ")\n",
    "test_backend.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first round has finished now. Let's see if we can repoduce all of that as intended.\n",
    "\n",
    "## Do it all again\n",
    "\n",
    "When we load a model instance from the HDF5 storage, all the settings, i.e. the graph, the diagnostic modalities and the loaded data, should still be the same as in the beginning. So let's check that with some `assert`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "recovered_model = lymph.utils.system_from_hdf(\n",
    "    filename=demo_hdf_file,\n",
    "    name=\"original/model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('tumor', 'primary'): ['I', 'II', 'III', 'IV'],\n",
       " ('lnl', 'I'): ['II'],\n",
       " ('lnl', 'II'): ['III'],\n",
       " ('lnl', 'III'): ['IV'],\n",
       " ('lnl', 'IV'): []}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert recovered_model.graph == graph, \"Wrong graph!\"\n",
    "recovered_model.graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MRI': [0.63, 0.81], 'PET': [0.86, 0.79]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert recovered_model.modalities == diagnostic_spsn, \"Wrong diagnostic modalities!\"\n",
    "recovered_model.modalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"8\" halign=\"left\">MRI</th>\n",
       "      <th colspan=\"8\" halign=\"left\">PET</th>\n",
       "      <th>info</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">contra</th>\n",
       "      <th colspan=\"4\" halign=\"left\">ipsi</th>\n",
       "      <th colspan=\"4\" halign=\"left\">contra</th>\n",
       "      <th colspan=\"4\" halign=\"left\">ipsi</th>\n",
       "      <th>tumor</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>I</th>\n",
       "      <th>II</th>\n",
       "      <th>III</th>\n",
       "      <th>IV</th>\n",
       "      <th>I</th>\n",
       "      <th>II</th>\n",
       "      <th>III</th>\n",
       "      <th>IV</th>\n",
       "      <th>I</th>\n",
       "      <th>II</th>\n",
       "      <th>III</th>\n",
       "      <th>IV</th>\n",
       "      <th>I</th>\n",
       "      <th>II</th>\n",
       "      <th>III</th>\n",
       "      <th>IV</th>\n",
       "      <th>t_stage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>late</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>early</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>late</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>late</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>late</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>early</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>late</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>late</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>early</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>late</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       MRI                                                     PET         \\\n",
       "    contra                        ipsi                      contra          \n",
       "         I     II    III     IV      I     II    III     IV      I     II   \n",
       "0    False   True  False  False   True   True  False   True   True  False   \n",
       "1    False  False  False  False  False   True   True   True  False  False   \n",
       "2    False   True  False  False  False  False   True   True  False   True   \n",
       "3     True  False  False  False  False   True   True  False  False  False   \n",
       "4    False  False  False  False   True  False   True   True  False  False   \n",
       "..     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "195  False  False   True   True   True  False   True   True  False  False   \n",
       "196   True  False   True  False  False   True   True  False  False   True   \n",
       "197  False   True  False  False   True   True   True   True  False   True   \n",
       "198   True  False   True   True   True   True  False  False  False  False   \n",
       "199  False   True  False   True  False  False   True  False   True   True   \n",
       "\n",
       "                                                 info  \n",
       "                    ipsi                        tumor  \n",
       "       III     IV      I     II    III     IV t_stage  \n",
       "0    False  False  False   True   True   True    late  \n",
       "1    False  False  False  False   True  False   early  \n",
       "2    False  False  False  False  False   True    late  \n",
       "3    False  False  False  False   True  False    late  \n",
       "4    False  False  False  False   True   True    late  \n",
       "..     ...    ...    ...    ...    ...    ...     ...  \n",
       "195  False  False  False   True   True  False   early  \n",
       "196   True  False  False   True  False  False    late  \n",
       "197  False  False   True  False  False   True    late  \n",
       "198  False  False  False  False  False  False   early  \n",
       "199   True   True  False  False  False  False    late  \n",
       "\n",
       "[200 rows x 17 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assert np.all(recovered_model.patient_data == synthetic_data), \"Wrong data!\"\n",
    "recovered_model.patient_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The recovery worked! Since we want to do another sampling round which itself should be reproducable as well, we can immediately store the recovered model in a new group of the HDF5 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rmnldwg/repos/lymph/.venv/lib/python3.8/site-packages/tables/attributeset.py:291: DataTypeWarning: Unsupported type for attribute 'base_symmetric' in node 'model'. Offending HDF5 class: 8\n",
      "  value = self._g_getattr(self._v_node, name)\n",
      "/home/rmnldwg/repos/lymph/.venv/lib/python3.8/site-packages/tables/attributeset.py:291: DataTypeWarning: Unsupported type for attribute 'trans_symmetric' in node 'model'. Offending HDF5 class: 8\n",
      "  value = self._g_getattr(self._v_node, name)\n"
     ]
    }
   ],
   "source": [
    "recovered_model.to_hdf(\n",
    "    filename=demo_hdf_file,\n",
    "    name=\"recovered/model\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the `EnsembleSampler`. We can recover the number of walkers and dimension from the previously stored HDF5 file. Note that I use two backends: One for retrieving the shape of the stored chain, which accesses the HDF5 group of the original sampling round. The however, I set up a new group for the second sampling round. The reason for this is that I don't want to call the `reset` method of the backend on my stored samples, thereby deleting them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting sampling\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [09:03<00:00,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max. number of steps reached\n",
      "Acceptance fraction = 23.22%\n",
      "Mean autocorrelation time = 22.14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tmp_backend = emcee.backends.HDFBackend(\n",
    "    filename=demo_hdf_file,\n",
    "    name=\"original/samples\"\n",
    ")\n",
    "nwalkers, ndim = tmp_backend.shape\n",
    "\n",
    "recovered_backend = emcee.backends.HDFBackend(\n",
    "    filename=demo_hdf_file,\n",
    "    name=\"recovered/samples\"\n",
    ")\n",
    "recovered_backend.reset(nwalkers, ndim)\n",
    "\n",
    "with Pool() as pool:\n",
    "    recovered_sampler = lymph.utils.EnsembleSampler(\n",
    "        nwalkers, ndim,\n",
    "        log_prob_fn, args=[recovered_model],\n",
    "        pool=pool, backend=recovered_backend\n",
    "    )\n",
    "    acor_list = recovered_sampler.run_sampling(max_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, it required relatively few stops to reproduce a sampling round. Just don't forget the log-probability function, as that is hard to store anywhere in an HDF5 file.\n",
    "\n",
    "Beyond that one can of course use the [h5py](https://docs.h5py.org/en/stable/) package or `pandas`' implemented capabilities to interact with the HDF5 file format to store and retrieve even more information, like a description of what was done or what exactly the log-likelihood does."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1b6eded5f386e55fd051b894079e4370359bf13f51a44183870a4399bfd4d593"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit ('.venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
